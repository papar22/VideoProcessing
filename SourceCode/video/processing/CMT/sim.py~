
import argparse
import cv2
from numpy import empty, nan
import os
import sys
import time

import CMT
import numpy as np
import util


CMT = CMT.CMT()

parser = argparse.ArgumentParser(description='Track an object.')

parser.add_argument('inputpath', nargs='?', help='The input path.')
parser.add_argument('--output-dir', dest='output', help='Specify a directory for output data.')

parser.add_argument('--no-scale', dest='estimate_scale', action='store_false', help='Disable scale estimation')
parser.add_argument('--with-rotation', dest='estimate_rotation', action='store_true', help='Enable rotation estimation')
parser.add_argument('--bbox', dest='bbox', help='Specify initial bounding box.')


parser.add_argument('--quiet', dest='quiet', action='store_true', help='Do not show graphical output (Useful in combination with --output-dir ).')
parser.add_argument('--skip', dest='skip', action='store', default=None, help='Skip the first n frames', type=int)

args = parser.parse_args()

CMT.estimate_scale = args.estimate_scale
CMT.estimate_rotation = args.estimate_rotation




# Clean up
cv2.destroyAllWindows()



if args.inputpath is not None:

	# If a path to a file was given, assume it is a single video file
	if os.path.isfile(args.inputpath):
		cap = cv2.VideoCapture(args.inputpath)

		#Skip first frames if required
		if args.skip is not None:
			cap.set(cv2.cv.CV_CAP_PROP_POS_FRAMES, args.skip)


	# Otherwise assume it is a format string for reading images
	else:
		cap = util.FileVideoCapture(args.inputpath)

		#Skip first frames if required
		if args.skip is not None:
			cap.frame = 1 + args.skip


else:
	# If no input path was specified, open camera device
	sys.exit("Error: no input path was specified")


# Read first frame
status, im0 = cap.read()
im_gray0 = cv2.cvtColor(im0, cv2.COLOR_BGR2GRAY)
im_draw = np.copy(im0)

if args.bbox is not None:
	# Try to disassemble user specified bounding box
	values = args.bbox.split(',')
	try:
		values = [int(v) for v in values]
	except:
		raise Exception('Unable to parse bounding box')
	if len(values) != 4:
		raise Exception('Bounding box must have exactly 4 elements')
	bbox = np.array(values)

	# Convert to point representation, adding singleton dimension
	bbox = util.bb2pts(bbox[None, :])

	# Squeeze
	bbox = bbox[0, :]

	tl = bbox[:2]
	br = bbox[2:4]
else:
	# Get rectangle input from user
	(tl, br) = util.get_rect(im_draw)

print 'using', tl, br, 'as init bb'



CMT.initialise(im_gray0, tl, br)

frame = 1

finalCoordinates = []

while True:
    # Read image
    status, im = cap.read()
    if not status:
        break
    im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
    im_draw = np.copy(im)

    tic = time.time()
    CMT.process_frame(im_gray)
    toc = time.time()
    
    finalCoordinates.append((CMT.tl, CMT.tr, CMT.br, CMT.bl))
    # saving the results on the files
    if args.output is not None:
		# Bounding box
		with open('{0}/bbox_{1:08d}.csv'.format(args.output, frame), 'w') as f:
			f.write('x y\n')
			# Duplicate entry tl is not a mistake, as it is used as a drawing instruction
			np.savetxt(f, np.array((CMT.tl, CMT.tr, CMT.br, CMT.bl, CMT.tl)), fmt='%.2f') 
    
    # Remember image
    im_prev = im_gray

    # Advance frame number
    frame += 1

    print '{5:04d}: center: {0:.2f},{1:.2f} scale: {2:.2f}, active: {3:03d}, {4:04.0f}ms'.format(CMT.center[0], CMT.center[1], CMT.scale_estimate, CMT.active_keypoints.shape[0], 1000 * (toc - tic), frame)
print (finalCoordinates[0])
